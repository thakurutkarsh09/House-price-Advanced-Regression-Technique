{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23b914ee088>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23b92831048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23b9284ce08>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling the Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160         21.0     1936            4            7       1970   \n",
       "1455         160         21.0     1894            4            5       1970   \n",
       "1456          20        160.0    20000            5            7       1960   \n",
       "1457          85         62.0    10441            5            5       1992   \n",
       "1458          60         74.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0             2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1             1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2             2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3             1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4             2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "...            ...         ...         ...         ...  ...   ...   ...  ...   \n",
       "1454          1970         0.0         0.0         0.0  ...     0     0    1   \n",
       "1455          1970         0.0       252.0         0.0  ...     0     0    1   \n",
       "1456          1996         0.0      1224.0         0.0  ...     0     0    1   \n",
       "1457          1992         0.0       337.0         0.0  ...     0     0    1   \n",
       "1458          1994        94.0       758.0         0.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1          1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2          2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3          1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4          2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction and algorithm\n",
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129051.695, 150099.22 , 196159.06 , ..., 169300.45 , 108080.62 ,\n",
       "       233303.56 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample submission file contains salesprice\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction and algorithm\n",
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import  randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "             min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample submission file contains salesprice\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 175)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 135988.5781 - val_loss: 56795.9922\n",
      "Epoch 2/1000\n",
      "231/231 [==============================] - 0s 941us/step - loss: 67591.0703 - val_loss: 53546.1289\n",
      "Epoch 3/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 62647.1953 - val_loss: 50967.8906\n",
      "Epoch 4/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 59710.2695 - val_loss: 50542.2305\n",
      "Epoch 5/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 56911.5508 - val_loss: 46399.7305\n",
      "Epoch 6/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 53570.5312 - val_loss: 42127.7188\n",
      "Epoch 7/1000\n",
      "231/231 [==============================] - 0s 968us/step - loss: 50610.9375 - val_loss: 39989.7305\n",
      "Epoch 8/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 47614.0156 - val_loss: 38741.2109\n",
      "Epoch 9/1000\n",
      "231/231 [==============================] - 0s 976us/step - loss: 44844.6680 - val_loss: 35628.7344\n",
      "Epoch 10/1000\n",
      "231/231 [==============================] - 0s 939us/step - loss: 42481.2031 - val_loss: 33436.5195\n",
      "Epoch 11/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 40152.7734 - val_loss: 32787.9922\n",
      "Epoch 12/1000\n",
      "231/231 [==============================] - 0s 869us/step - loss: 39063.7305 - val_loss: 32282.8848\n",
      "Epoch 13/1000\n",
      "231/231 [==============================] - 0s 926us/step - loss: 38127.0586 - val_loss: 31742.7559\n",
      "Epoch 14/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 37448.0039 - val_loss: 32056.9180\n",
      "Epoch 15/1000\n",
      "231/231 [==============================] - 0s 930us/step - loss: 36841.6016 - val_loss: 31939.4805\n",
      "Epoch 16/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 36642.3867 - val_loss: 32557.4863\n",
      "Epoch 17/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 36647.3750 - val_loss: 32221.5469\n",
      "Epoch 18/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 36395.8828 - val_loss: 31828.3086\n",
      "Epoch 19/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 36029.7812 - val_loss: 31818.7383\n",
      "Epoch 20/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 35835.5781 - val_loss: 31837.6367\n",
      "Epoch 21/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 35558.3320 - val_loss: 31945.1582\n",
      "Epoch 22/1000\n",
      "231/231 [==============================] - 0s 910us/step - loss: 35616.3906 - val_loss: 31820.7344\n",
      "Epoch 23/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 35506.6016 - val_loss: 31793.8164\n",
      "Epoch 24/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 35166.2617 - val_loss: 32012.8320\n",
      "Epoch 25/1000\n",
      "231/231 [==============================] - 0s 985us/step - loss: 35190.7227 - val_loss: 31972.3223\n",
      "Epoch 26/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 35313.3711 - val_loss: 31740.3086\n",
      "Epoch 27/1000\n",
      "231/231 [==============================] - 0s 975us/step - loss: 35336.2305 - val_loss: 31908.6309\n",
      "Epoch 28/1000\n",
      "231/231 [==============================] - 0s 969us/step - loss: 35005.4297 - val_loss: 31659.0781\n",
      "Epoch 29/1000\n",
      "231/231 [==============================] - 0s 961us/step - loss: 35016.0430 - val_loss: 32249.8574\n",
      "Epoch 30/1000\n",
      "231/231 [==============================] - 0s 983us/step - loss: 35044.0469 - val_loss: 31536.3262\n",
      "Epoch 31/1000\n",
      "231/231 [==============================] - 0s 951us/step - loss: 35150.4102 - val_loss: 31565.1719\n",
      "Epoch 32/1000\n",
      "231/231 [==============================] - 0s 962us/step - loss: 34785.3789 - val_loss: 31651.6953\n",
      "Epoch 33/1000\n",
      "231/231 [==============================] - 0s 933us/step - loss: 34618.6406 - val_loss: 31612.1562\n",
      "Epoch 34/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 34878.9883 - val_loss: 31396.3535\n",
      "Epoch 35/1000\n",
      "231/231 [==============================] - 0s 968us/step - loss: 34579.9102 - val_loss: 31276.4688\n",
      "Epoch 36/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34317.5430 - val_loss: 31835.4590\n",
      "Epoch 37/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34306.1875 - val_loss: 31324.1875\n",
      "Epoch 38/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34296.6523 - val_loss: 31169.2969\n",
      "Epoch 39/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34518.4375 - val_loss: 31139.8203\n",
      "Epoch 40/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34256.9805 - val_loss: 31180.8984\n",
      "Epoch 41/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 34474.1055 - val_loss: 31304.6309\n",
      "Epoch 42/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 33998.6836 - val_loss: 31471.6641\n",
      "Epoch 43/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 34253.3555 - val_loss: 31176.7617\n",
      "Epoch 44/1000\n",
      "231/231 [==============================] - 0s 985us/step - loss: 34135.7422 - val_loss: 31017.9277\n",
      "Epoch 45/1000\n",
      "231/231 [==============================] - 0s 971us/step - loss: 33797.7578 - val_loss: 30773.9473\n",
      "Epoch 46/1000\n",
      "231/231 [==============================] - 0s 974us/step - loss: 33712.7852 - val_loss: 30984.3047\n",
      "Epoch 47/1000\n",
      "231/231 [==============================] - 0s 999us/step - loss: 33799.9180 - val_loss: 31242.7461\n",
      "Epoch 48/1000\n",
      "231/231 [==============================] - 0s 947us/step - loss: 33932.9375 - val_loss: 30701.1152\n",
      "Epoch 49/1000\n",
      "231/231 [==============================] - 0s 965us/step - loss: 33749.0977 - val_loss: 31555.9922\n",
      "Epoch 50/1000\n",
      "231/231 [==============================] - 0s 983us/step - loss: 33472.0352 - val_loss: 30703.0293\n",
      "Epoch 51/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 33697.1836 - val_loss: 30493.7676\n",
      "Epoch 52/1000\n",
      "231/231 [==============================] - 0s 948us/step - loss: 33441.6680 - val_loss: 30579.1719\n",
      "Epoch 53/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 33375.2227 - val_loss: 30380.4531\n",
      "Epoch 54/1000\n",
      "231/231 [==============================] - 0s 955us/step - loss: 33168.6562 - val_loss: 31055.4219\n",
      "Epoch 55/1000\n",
      "231/231 [==============================] - 0s 974us/step - loss: 33009.2422 - val_loss: 30226.6621\n",
      "Epoch 56/1000\n",
      "231/231 [==============================] - 0s 982us/step - loss: 33070.1523 - val_loss: 30408.3262\n",
      "Epoch 57/1000\n",
      "231/231 [==============================] - 0s 971us/step - loss: 32837.1875 - val_loss: 30430.0547\n",
      "Epoch 58/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 33013.8789 - val_loss: 30081.1777\n",
      "Epoch 59/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 32867.7344 - val_loss: 30182.3301\n",
      "Epoch 60/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 32627.8574 - val_loss: 30114.4473\n",
      "Epoch 61/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 32654.8262 - val_loss: 30431.2891\n",
      "Epoch 62/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 32570.1465 - val_loss: 29986.5332\n",
      "Epoch 63/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 32663.1426 - val_loss: 30515.8438\n",
      "Epoch 64/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 32492.4688 - val_loss: 29912.8867\n",
      "Epoch 65/1000\n",
      "231/231 [==============================] - 0s 894us/step - loss: 32369.1953 - val_loss: 29810.8496\n",
      "Epoch 66/1000\n",
      "231/231 [==============================] - 0s 905us/step - loss: 32300.7500 - val_loss: 29794.9004\n",
      "Epoch 67/1000\n",
      "231/231 [==============================] - 0s 950us/step - loss: 32181.7676 - val_loss: 29874.3359\n",
      "Epoch 68/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 32192.0039 - val_loss: 29577.8691\n",
      "Epoch 69/1000\n",
      "231/231 [==============================] - 0s 990us/step - loss: 32089.4863 - val_loss: 29723.8613\n",
      "Epoch 70/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 32406.9688 - val_loss: 30040.8379\n",
      "Epoch 71/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 32107.7363 - val_loss: 29507.4590\n",
      "Epoch 72/1000\n",
      "231/231 [==============================] - 0s 956us/step - loss: 32117.2910 - val_loss: 29687.4551\n",
      "Epoch 73/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 32064.6348 - val_loss: 29391.6816\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 950us/step - loss: 31869.4727 - val_loss: 29292.9980\n",
      "Epoch 75/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 31531.5039 - val_loss: 29701.3379\n",
      "Epoch 76/1000\n",
      "231/231 [==============================] - 0s 917us/step - loss: 31994.9473 - val_loss: 29264.5469\n",
      "Epoch 77/1000\n",
      "231/231 [==============================] - 0s 919us/step - loss: 31646.6289 - val_loss: 29415.8164\n",
      "Epoch 78/1000\n",
      "231/231 [==============================] - 0s 974us/step - loss: 32196.5137 - val_loss: 29547.0293\n",
      "Epoch 79/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 31690.6914 - val_loss: 29945.1582\n",
      "Epoch 80/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31727.5391 - val_loss: 29176.8418\n",
      "Epoch 81/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31633.9297 - val_loss: 29331.8164\n",
      "Epoch 82/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31506.4160 - val_loss: 29148.4609\n",
      "Epoch 83/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31509.5625 - val_loss: 29905.9512\n",
      "Epoch 84/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31612.7402 - val_loss: 29132.9531\n",
      "Epoch 85/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31567.6250 - val_loss: 29064.5840\n",
      "Epoch 86/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 31325.8164 - val_loss: 28942.0293\n",
      "Epoch 87/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 31460.7539 - val_loss: 29190.5098\n",
      "Epoch 88/1000\n",
      "231/231 [==============================] - 0s 954us/step - loss: 31350.9375 - val_loss: 28889.3477\n",
      "Epoch 89/1000\n",
      "231/231 [==============================] - 2s 7ms/step - loss: 31525.0410 - val_loss: 28781.0312\n",
      "Epoch 90/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30953.4648 - val_loss: 28837.0859\n",
      "Epoch 91/1000\n",
      "231/231 [==============================] - 0s 977us/step - loss: 31425.0215 - val_loss: 28735.7910\n",
      "Epoch 92/1000\n",
      "231/231 [==============================] - 0s 962us/step - loss: 31105.1016 - val_loss: 28680.0137\n",
      "Epoch 93/1000\n",
      "231/231 [==============================] - 0s 981us/step - loss: 31016.5312 - val_loss: 29487.3164\n",
      "Epoch 94/1000\n",
      "231/231 [==============================] - 0s 984us/step - loss: 30936.6250 - val_loss: 28637.4531\n",
      "Epoch 95/1000\n",
      "231/231 [==============================] - 0s 948us/step - loss: 31246.7402 - val_loss: 28688.3613\n",
      "Epoch 96/1000\n",
      "231/231 [==============================] - 0s 979us/step - loss: 31275.4062 - val_loss: 28536.3828\n",
      "Epoch 97/1000\n",
      "231/231 [==============================] - 0s 940us/step - loss: 31179.9609 - val_loss: 29487.8301\n",
      "Epoch 98/1000\n",
      "231/231 [==============================] - 0s 898us/step - loss: 31457.0703 - val_loss: 29335.6055\n",
      "Epoch 99/1000\n",
      "231/231 [==============================] - 0s 998us/step - loss: 31220.7109 - val_loss: 28539.6973\n",
      "Epoch 100/1000\n",
      "231/231 [==============================] - 0s 970us/step - loss: 30906.7715 - val_loss: 28497.3984\n",
      "Epoch 101/1000\n",
      "231/231 [==============================] - 0s 972us/step - loss: 31080.0098 - val_loss: 28444.9844\n",
      "Epoch 102/1000\n",
      "231/231 [==============================] - 0s 969us/step - loss: 31076.1914 - val_loss: 28585.5098\n",
      "Epoch 103/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 30769.2949 - val_loss: 28437.3750\n",
      "Epoch 104/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 30954.3164 - val_loss: 28562.4824\n",
      "Epoch 105/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30885.5723 - val_loss: 28269.4629\n",
      "Epoch 106/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30748.3672 - val_loss: 29100.6172\n",
      "Epoch 107/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30771.6113 - val_loss: 28272.4531\n",
      "Epoch 108/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30827.7324 - val_loss: 28291.4238\n",
      "Epoch 109/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30890.3164 - val_loss: 28275.8496\n",
      "Epoch 110/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30577.7148 - val_loss: 28172.5234\n",
      "Epoch 111/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30688.8848 - val_loss: 28239.2617\n",
      "Epoch 112/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30517.1973 - val_loss: 28182.0078\n",
      "Epoch 113/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30730.0723 - val_loss: 28138.8906\n",
      "Epoch 114/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30535.4922 - val_loss: 28117.9121\n",
      "Epoch 115/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30600.0273 - val_loss: 28096.7930\n",
      "Epoch 116/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30527.2402 - val_loss: 29463.1152\n",
      "Epoch 117/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30338.2422 - val_loss: 29157.4844\n",
      "Epoch 118/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30381.8613 - val_loss: 28400.7930\n",
      "Epoch 119/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30357.0176 - val_loss: 28086.4883\n",
      "Epoch 120/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30713.3125 - val_loss: 27927.1914\n",
      "Epoch 121/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30141.4453 - val_loss: 27980.5801\n",
      "Epoch 122/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30538.1035 - val_loss: 27941.6719\n",
      "Epoch 123/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30199.4453 - val_loss: 28149.0723\n",
      "Epoch 124/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30468.3984 - val_loss: 27748.3184\n",
      "Epoch 125/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30343.3398 - val_loss: 27753.5195\n",
      "Epoch 126/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30054.0723 - val_loss: 27701.0391\n",
      "Epoch 127/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30572.3027 - val_loss: 27811.9590\n",
      "Epoch 128/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 30165.6914 - val_loss: 27654.6465\n",
      "Epoch 129/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30145.1426 - val_loss: 27669.1992\n",
      "Epoch 130/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30245.7090 - val_loss: 27570.4277\n",
      "Epoch 131/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29930.0137 - val_loss: 27515.0078\n",
      "Epoch 132/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 30295.1641 - val_loss: 27489.9648\n",
      "Epoch 133/1000\n",
      "231/231 [==============================] - 0s 961us/step - loss: 30077.6348 - val_loss: 28422.4961\n",
      "Epoch 134/1000\n",
      "231/231 [==============================] - 0s 977us/step - loss: 30105.7949 - val_loss: 27817.6523\n",
      "Epoch 135/1000\n",
      "231/231 [==============================] - 0s 946us/step - loss: 30275.2676 - val_loss: 27368.2656\n",
      "Epoch 136/1000\n",
      "231/231 [==============================] - 0s 940us/step - loss: 30166.3203 - val_loss: 27317.2090\n",
      "Epoch 137/1000\n",
      "231/231 [==============================] - 0s 967us/step - loss: 29886.4609 - val_loss: 27398.1621\n",
      "Epoch 138/1000\n",
      "231/231 [==============================] - 0s 967us/step - loss: 30135.9551 - val_loss: 27330.5059\n",
      "Epoch 139/1000\n",
      "231/231 [==============================] - 0s 947us/step - loss: 29928.8477 - val_loss: 27313.3691\n",
      "Epoch 140/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29979.5527 - val_loss: 28219.7930\n",
      "Epoch 141/1000\n",
      "231/231 [==============================] - 0s 975us/step - loss: 29704.1348 - val_loss: 27226.1855\n",
      "Epoch 142/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29768.4785 - val_loss: 27217.2852\n",
      "Epoch 143/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29800.5312 - val_loss: 27326.4375\n",
      "Epoch 144/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29369.4199 - val_loss: 27292.9805\n",
      "Epoch 145/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29486.2402 - val_loss: 27398.7637\n",
      "Epoch 146/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29685.6738 - val_loss: 27494.1738\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 29514.5723 - val_loss: 27340.7109\n",
      "Epoch 148/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 29355.9766 - val_loss: 27047.3145\n",
      "Epoch 149/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 29428.7051 - val_loss: 26982.9199\n",
      "Epoch 150/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29687.0625 - val_loss: 26897.0215\n",
      "Epoch 151/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29664.1387 - val_loss: 26941.8203\n",
      "Epoch 152/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29464.4590 - val_loss: 27105.0488\n",
      "Epoch 153/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29575.7012 - val_loss: 26900.3789\n",
      "Epoch 154/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29217.8789 - val_loss: 26773.1602\n",
      "Epoch 155/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29372.3828 - val_loss: 26755.6445\n",
      "Epoch 156/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28999.6797 - val_loss: 27266.9453\n",
      "Epoch 157/1000\n",
      "231/231 [==============================] - 0s 885us/step - loss: 29455.8438 - val_loss: 26654.6699\n",
      "Epoch 158/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29052.0078 - val_loss: 28503.3516\n",
      "Epoch 159/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 29315.6602 - val_loss: 26890.3203\n",
      "Epoch 160/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 29173.2188 - val_loss: 26992.2852\n",
      "Epoch 161/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 29546.8613 - val_loss: 26606.0859\n",
      "Epoch 162/1000\n",
      "231/231 [==============================] - 0s 969us/step - loss: 29425.6074 - val_loss: 26423.9414\n",
      "Epoch 163/1000\n",
      "231/231 [==============================] - 0s 898us/step - loss: 29028.6738 - val_loss: 26392.5410\n",
      "Epoch 164/1000\n",
      "231/231 [==============================] - 0s 939us/step - loss: 29136.4922 - val_loss: 26367.7520\n",
      "Epoch 165/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 29110.3164 - val_loss: 26472.6309\n",
      "Epoch 166/1000\n",
      "231/231 [==============================] - 0s 871us/step - loss: 28997.1562 - val_loss: 29009.2852\n",
      "Epoch 167/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 29125.5488 - val_loss: 26217.7969\n",
      "Epoch 168/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28772.2461 - val_loss: 27464.7793\n",
      "Epoch 169/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29056.5664 - val_loss: 26253.5293\n",
      "Epoch 170/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28925.8203 - val_loss: 26383.5527\n",
      "Epoch 171/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28903.4258 - val_loss: 26110.7656\n",
      "Epoch 172/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 29141.3340 - val_loss: 26008.3086\n",
      "Epoch 173/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28795.2500 - val_loss: 26116.3926\n",
      "Epoch 174/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28705.4707 - val_loss: 26591.6992\n",
      "Epoch 175/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28586.2969 - val_loss: 26234.4180\n",
      "Epoch 176/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28889.3105 - val_loss: 26131.5859\n",
      "Epoch 177/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28780.3438 - val_loss: 25855.3145\n",
      "Epoch 178/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28430.3750 - val_loss: 25753.1152\n",
      "Epoch 179/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28288.6230 - val_loss: 25957.6875\n",
      "Epoch 180/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28785.1582 - val_loss: 25705.0586\n",
      "Epoch 181/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28673.6582 - val_loss: 25631.5957\n",
      "Epoch 182/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28569.6270 - val_loss: 25512.9922\n",
      "Epoch 183/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28321.6719 - val_loss: 25626.2168\n",
      "Epoch 184/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28168.3477 - val_loss: 25378.5586\n",
      "Epoch 185/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28257.9609 - val_loss: 26098.1758\n",
      "Epoch 186/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28257.6387 - val_loss: 25201.5391\n",
      "Epoch 187/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27894.2891 - val_loss: 25332.6797\n",
      "Epoch 188/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27970.4219 - val_loss: 25129.7344\n",
      "Epoch 189/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28139.5625 - val_loss: 24967.1953\n",
      "Epoch 190/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28208.5664 - val_loss: 25053.6777\n",
      "Epoch 191/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27870.5820 - val_loss: 25151.4570\n",
      "Epoch 192/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28164.4746 - val_loss: 24984.4023\n",
      "Epoch 193/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 28019.8594 - val_loss: 24799.5762\n",
      "Epoch 194/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27934.6309 - val_loss: 24601.2656\n",
      "Epoch 195/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27786.4395 - val_loss: 24593.1270\n",
      "Epoch 196/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27675.6934 - val_loss: 24884.0234\n",
      "Epoch 197/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27474.6797 - val_loss: 24520.3945\n",
      "Epoch 198/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27315.4824 - val_loss: 24867.4238\n",
      "Epoch 199/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27524.3242 - val_loss: 24714.4375\n",
      "Epoch 200/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27525.8594 - val_loss: 24505.8203\n",
      "Epoch 201/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 27543.7266 - val_loss: 24350.9043\n",
      "Epoch 202/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27470.7266 - val_loss: 26902.4844\n",
      "Epoch 203/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27450.4629 - val_loss: 24658.2441\n",
      "Epoch 204/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27327.5918 - val_loss: 24097.3398\n",
      "Epoch 205/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27270.1895 - val_loss: 24085.4668\n",
      "Epoch 206/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27417.5098 - val_loss: 24738.6445\n",
      "Epoch 207/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27279.8145 - val_loss: 23758.6289\n",
      "Epoch 208/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27387.7383 - val_loss: 23669.5879\n",
      "Epoch 209/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27251.2754 - val_loss: 23698.2773\n",
      "Epoch 210/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26954.5254 - val_loss: 23760.9961\n",
      "Epoch 211/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27130.6328 - val_loss: 24037.7715\n",
      "Epoch 212/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27020.2363 - val_loss: 23450.7441\n",
      "Epoch 213/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26982.0977 - val_loss: 24133.3066\n",
      "Epoch 214/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 27197.0703 - val_loss: 23417.3203\n",
      "Epoch 215/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26886.4941 - val_loss: 23475.6895\n",
      "Epoch 216/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26936.3555 - val_loss: 23349.0840\n",
      "Epoch 217/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26727.5547 - val_loss: 23178.8633\n",
      "Epoch 218/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26539.8203 - val_loss: 23242.7344\n",
      "Epoch 219/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26495.7910 - val_loss: 22731.6895\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 26331.1738 - val_loss: 22982.6914\n",
      "Epoch 221/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25971.3574 - val_loss: 22845.9570\n",
      "Epoch 222/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26309.3809 - val_loss: 22680.3730\n",
      "Epoch 223/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26287.7363 - val_loss: 22804.2324\n",
      "Epoch 224/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26302.8242 - val_loss: 22524.8633\n",
      "Epoch 225/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26367.9980 - val_loss: 22380.0410\n",
      "Epoch 226/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26091.5176 - val_loss: 22521.2480\n",
      "Epoch 227/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25927.1738 - val_loss: 23726.7852\n",
      "Epoch 228/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25908.4766 - val_loss: 22116.6934\n",
      "Epoch 229/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25736.2891 - val_loss: 22063.0488\n",
      "Epoch 230/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26043.8496 - val_loss: 22252.0352\n",
      "Epoch 231/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 26127.2676 - val_loss: 22876.9727\n",
      "Epoch 232/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25803.9727 - val_loss: 21972.9238\n",
      "Epoch 233/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25991.2090 - val_loss: 22529.8770\n",
      "Epoch 234/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25544.4609 - val_loss: 22074.7891\n",
      "Epoch 235/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25703.3984 - val_loss: 21683.8223\n",
      "Epoch 236/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25501.5605 - val_loss: 21567.8926\n",
      "Epoch 237/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25430.4727 - val_loss: 22212.2773\n",
      "Epoch 238/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25678.5703 - val_loss: 21678.6855\n",
      "Epoch 239/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25706.9512 - val_loss: 22130.1582\n",
      "Epoch 240/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25542.4785 - val_loss: 21026.4668\n",
      "Epoch 241/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25261.8125 - val_loss: 21570.3750\n",
      "Epoch 242/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25513.7246 - val_loss: 21623.9609\n",
      "Epoch 243/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 25161.5078 - val_loss: 21549.8457\n",
      "Epoch 244/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25309.8516 - val_loss: 20820.3496\n",
      "Epoch 245/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24922.3320 - val_loss: 20915.0488\n",
      "Epoch 246/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25068.6934 - val_loss: 21407.1816\n",
      "Epoch 247/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25009.3242 - val_loss: 20760.9316\n",
      "Epoch 248/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24786.2637 - val_loss: 20516.6191\n",
      "Epoch 249/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24648.4453 - val_loss: 20309.9277\n",
      "Epoch 250/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 25077.9727 - val_loss: 21284.7773\n",
      "Epoch 251/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24905.8711 - val_loss: 20713.8594\n",
      "Epoch 252/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 24510.3047 - val_loss: 20275.7109\n",
      "Epoch 253/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 25050.4258 - val_loss: 20203.8281\n",
      "Epoch 254/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24525.2324 - val_loss: 20181.5234\n",
      "Epoch 255/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 24371.7461 - val_loss: 20670.5254\n",
      "Epoch 256/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 24501.8047 - val_loss: 19884.4355\n",
      "Epoch 257/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24125.9238 - val_loss: 20090.6777\n",
      "Epoch 258/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24193.0039 - val_loss: 19798.3848\n",
      "Epoch 259/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24253.6680 - val_loss: 21323.2207\n",
      "Epoch 260/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24558.3281 - val_loss: 19853.7930\n",
      "Epoch 261/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24502.3359 - val_loss: 19948.9316\n",
      "Epoch 262/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 24192.4590 - val_loss: 19802.4766\n",
      "Epoch 263/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24384.7480 - val_loss: 19674.8379\n",
      "Epoch 264/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24294.1367 - val_loss: 19849.3711\n",
      "Epoch 265/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 24135.4609 - val_loss: 19838.9961\n",
      "Epoch 266/1000\n",
      "231/231 [==============================] - 0s 989us/step - loss: 23950.3164 - val_loss: 20343.0176\n",
      "Epoch 267/1000\n",
      "231/231 [==============================] - 0s 978us/step - loss: 24239.6797 - val_loss: 19274.0625\n",
      "Epoch 268/1000\n",
      "231/231 [==============================] - 0s 995us/step - loss: 24085.3008 - val_loss: 19807.4590\n",
      "Epoch 269/1000\n",
      "231/231 [==============================] - 0s 972us/step - loss: 23818.9941 - val_loss: 18986.2754\n",
      "Epoch 270/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23364.9004 - val_loss: 19283.9473\n",
      "Epoch 271/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23775.2734 - val_loss: 20712.6172\n",
      "Epoch 272/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 24161.2324 - val_loss: 19234.7285\n",
      "Epoch 273/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23728.6348 - val_loss: 19239.9375\n",
      "Epoch 274/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23672.3594 - val_loss: 19259.0742\n",
      "Epoch 275/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23834.3945 - val_loss: 19392.3926\n",
      "Epoch 276/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23868.6055 - val_loss: 19715.5176\n",
      "Epoch 277/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23601.2363 - val_loss: 19221.8223\n",
      "Epoch 278/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23888.3496 - val_loss: 19235.7441\n",
      "Epoch 279/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23695.1816 - val_loss: 19269.3145\n",
      "Epoch 280/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23657.0723 - val_loss: 19853.1348\n",
      "Epoch 281/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23577.4473 - val_loss: 18913.9316\n",
      "Epoch 282/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23743.5332 - val_loss: 18493.8438\n",
      "Epoch 283/1000\n",
      "231/231 [==============================] - 0s 964us/step - loss: 23202.8594 - val_loss: 19731.2598\n",
      "Epoch 284/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23665.8867 - val_loss: 18663.1172\n",
      "Epoch 285/1000\n",
      "231/231 [==============================] - 0s 946us/step - loss: 23507.4355 - val_loss: 18931.4004\n",
      "Epoch 286/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23342.5547 - val_loss: 18360.7988\n",
      "Epoch 287/1000\n",
      "231/231 [==============================] - 0s 993us/step - loss: 23194.1797 - val_loss: 19560.2012\n",
      "Epoch 288/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23269.4043 - val_loss: 18896.9629\n",
      "Epoch 289/1000\n",
      "231/231 [==============================] - 0s 967us/step - loss: 23256.1289 - val_loss: 20940.3066\n",
      "Epoch 290/1000\n",
      "231/231 [==============================] - 0s 965us/step - loss: 23215.0938 - val_loss: 18921.4570\n",
      "Epoch 291/1000\n",
      "231/231 [==============================] - 0s 987us/step - loss: 22990.0078 - val_loss: 18528.2852\n",
      "Epoch 292/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23042.1797 - val_loss: 18151.3379\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 23470.2793 - val_loss: 18786.3301\n",
      "Epoch 294/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23054.1367 - val_loss: 18264.3652\n",
      "Epoch 295/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23164.3223 - val_loss: 19236.0391\n",
      "Epoch 296/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23239.5332 - val_loss: 20277.9277\n",
      "Epoch 297/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23193.6602 - val_loss: 18995.0117\n",
      "Epoch 298/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 23143.3223 - val_loss: 18524.5234\n",
      "Epoch 299/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22937.6641 - val_loss: 18359.5703\n",
      "Epoch 300/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 23165.1875 - val_loss: 18100.5020\n",
      "Epoch 301/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 23028.9570 - val_loss: 18352.1309\n",
      "Epoch 302/1000\n",
      "231/231 [==============================] - 0s 941us/step - loss: 22988.0605 - val_loss: 18059.6895\n",
      "Epoch 303/1000\n",
      "231/231 [==============================] - 0s 895us/step - loss: 22902.8281 - val_loss: 19506.2441\n",
      "Epoch 304/1000\n",
      "231/231 [==============================] - 0s 933us/step - loss: 22894.7539 - val_loss: 19572.7090\n",
      "Epoch 305/1000\n",
      "231/231 [==============================] - 0s 924us/step - loss: 22890.1660 - val_loss: 19249.3789\n",
      "Epoch 306/1000\n",
      "231/231 [==============================] - 0s 937us/step - loss: 22756.7676 - val_loss: 18144.3379\n",
      "Epoch 307/1000\n",
      "231/231 [==============================] - 0s 926us/step - loss: 22817.3633 - val_loss: 18538.5625\n",
      "Epoch 308/1000\n",
      "231/231 [==============================] - 0s 896us/step - loss: 22627.4062 - val_loss: 17761.2070\n",
      "Epoch 309/1000\n",
      "231/231 [==============================] - 0s 888us/step - loss: 22308.2383 - val_loss: 17951.8223\n",
      "Epoch 310/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22626.5742 - val_loss: 17686.3008\n",
      "Epoch 311/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22493.2559 - val_loss: 18212.9668\n",
      "Epoch 312/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22722.0000 - val_loss: 17620.7305\n",
      "Epoch 313/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22645.5391 - val_loss: 17745.1621\n",
      "Epoch 314/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22881.6875 - val_loss: 18037.5059\n",
      "Epoch 315/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22278.0410 - val_loss: 17784.8418\n",
      "Epoch 316/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22317.7676 - val_loss: 18412.9590\n",
      "Epoch 317/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22538.7949 - val_loss: 17892.9395\n",
      "Epoch 318/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22429.8066 - val_loss: 17867.2773\n",
      "Epoch 319/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22234.1641 - val_loss: 17529.0762\n",
      "Epoch 320/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22607.2969 - val_loss: 17672.7852\n",
      "Epoch 321/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22798.0762 - val_loss: 25049.1660\n",
      "Epoch 322/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22732.7285 - val_loss: 20646.1211\n",
      "Epoch 323/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22680.1523 - val_loss: 18796.8340\n",
      "Epoch 324/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22659.3535 - val_loss: 17686.9102\n",
      "Epoch 325/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22226.2695 - val_loss: 17601.5605\n",
      "Epoch 326/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22119.0371 - val_loss: 18480.7988\n",
      "Epoch 327/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22148.2109 - val_loss: 17687.4238\n",
      "Epoch 328/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22228.4844 - val_loss: 18206.0215\n",
      "Epoch 329/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22053.9102 - val_loss: 17614.2031\n",
      "Epoch 330/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22255.2266 - val_loss: 18782.7207\n",
      "Epoch 331/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22343.6445 - val_loss: 17889.3926\n",
      "Epoch 332/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22616.7852 - val_loss: 18513.6953\n",
      "Epoch 333/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22006.6133 - val_loss: 17610.3379\n",
      "Epoch 334/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21965.1738 - val_loss: 17705.6973\n",
      "Epoch 335/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22477.2988 - val_loss: 17506.9883\n",
      "Epoch 336/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22012.0195 - val_loss: 17147.8496\n",
      "Epoch 337/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22137.0625 - val_loss: 18693.3242\n",
      "Epoch 338/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22213.6621 - val_loss: 18626.1426\n",
      "Epoch 339/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21916.9922 - val_loss: 17635.0996\n",
      "Epoch 340/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21891.0176 - val_loss: 17601.5176\n",
      "Epoch 341/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22499.7734 - val_loss: 20118.7148\n",
      "Epoch 342/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21918.0469 - val_loss: 17483.0352\n",
      "Epoch 343/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21992.9844 - val_loss: 18426.5020\n",
      "Epoch 344/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22088.2109 - val_loss: 17825.9102\n",
      "Epoch 345/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22134.7344 - val_loss: 18482.2441\n",
      "Epoch 346/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21743.1406 - val_loss: 17206.9238\n",
      "Epoch 347/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22103.0918 - val_loss: 17942.0332\n",
      "Epoch 348/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21932.6211 - val_loss: 20130.8984\n",
      "Epoch 349/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22196.5488 - val_loss: 17495.9160\n",
      "Epoch 350/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22144.4805 - val_loss: 17503.5156\n",
      "Epoch 351/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21622.0391 - val_loss: 17699.9199\n",
      "Epoch 352/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21952.6328 - val_loss: 17056.6699\n",
      "Epoch 353/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21948.7168 - val_loss: 17868.5273\n",
      "Epoch 354/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21864.5293 - val_loss: 17056.9746\n",
      "Epoch 355/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22019.1387 - val_loss: 17989.0781\n",
      "Epoch 356/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21991.8359 - val_loss: 17064.9316\n",
      "Epoch 357/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 22145.9551 - val_loss: 17890.1582\n",
      "Epoch 358/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21702.2324 - val_loss: 17191.4844\n",
      "Epoch 359/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21766.6484 - val_loss: 16712.5273\n",
      "Epoch 360/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21706.9785 - val_loss: 17928.3926\n",
      "Epoch 361/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21781.5664 - val_loss: 16982.8086\n",
      "Epoch 362/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21364.0918 - val_loss: 19703.4961\n",
      "Epoch 363/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21665.5254 - val_loss: 16927.6992\n",
      "Epoch 364/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21801.3203 - val_loss: 17466.3848\n",
      "Epoch 365/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21420.5156 - val_loss: 17866.4141\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 21584.4766 - val_loss: 19456.6816\n",
      "Epoch 367/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21599.5215 - val_loss: 16656.9160\n",
      "Epoch 368/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21310.7246 - val_loss: 17461.7852\n",
      "Epoch 369/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21468.7168 - val_loss: 16970.5352\n",
      "Epoch 370/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21413.5195 - val_loss: 17556.2969\n",
      "Epoch 371/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21321.6211 - val_loss: 16917.0078\n",
      "Epoch 372/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21688.5273 - val_loss: 17257.3594\n",
      "Epoch 373/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21369.5391 - val_loss: 19674.1250\n",
      "Epoch 374/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21390.9297 - val_loss: 18529.8672\n",
      "Epoch 375/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21742.5078 - val_loss: 17249.0176\n",
      "Epoch 376/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21367.8789 - val_loss: 16760.8027\n",
      "Epoch 377/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21504.5859 - val_loss: 22963.5664\n",
      "Epoch 378/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21298.9062 - val_loss: 17093.6758\n",
      "Epoch 379/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21138.2949 - val_loss: 17092.9531\n",
      "Epoch 380/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21126.2793 - val_loss: 18305.3555\n",
      "Epoch 381/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21195.1973 - val_loss: 16614.0840\n",
      "Epoch 382/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21230.0879 - val_loss: 16719.6777\n",
      "Epoch 383/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21123.7441 - val_loss: 17962.6719\n",
      "Epoch 384/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21438.5859 - val_loss: 16402.8027\n",
      "Epoch 385/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20965.0254 - val_loss: 17243.5801\n",
      "Epoch 386/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20724.0273 - val_loss: 16781.4688\n",
      "Epoch 387/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21026.4922 - val_loss: 17042.3125\n",
      "Epoch 388/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21204.3047 - val_loss: 16285.3135\n",
      "Epoch 389/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21476.1875 - val_loss: 17066.6230\n",
      "Epoch 390/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21176.7227 - val_loss: 18116.1719\n",
      "Epoch 391/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21303.0566 - val_loss: 16272.1611\n",
      "Epoch 392/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21097.4219 - val_loss: 16140.6641\n",
      "Epoch 393/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21100.1289 - val_loss: 16329.7852\n",
      "Epoch 394/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20869.4395 - val_loss: 17490.6660\n",
      "Epoch 395/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20789.0508 - val_loss: 16796.9453\n",
      "Epoch 396/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20873.4141 - val_loss: 20443.5879\n",
      "Epoch 397/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21001.1133 - val_loss: 16749.9219\n",
      "Epoch 398/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21062.2930 - val_loss: 16501.7461\n",
      "Epoch 399/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20745.0684 - val_loss: 17485.2422\n",
      "Epoch 400/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21390.5195 - val_loss: 17734.4121\n",
      "Epoch 401/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20600.2422 - val_loss: 16415.5605\n",
      "Epoch 402/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20838.7344 - val_loss: 16479.5156\n",
      "Epoch 403/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 20657.6426 - val_loss: 16472.8008\n",
      "Epoch 404/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20431.6309 - val_loss: 16771.9570\n",
      "Epoch 405/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20795.8438 - val_loss: 17028.1211\n",
      "Epoch 406/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20849.4512 - val_loss: 17062.5273\n",
      "Epoch 407/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 21027.3105 - val_loss: 17110.2578\n",
      "Epoch 408/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20817.1465 - val_loss: 18358.9414\n",
      "Epoch 409/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20715.3379 - val_loss: 18500.6719\n",
      "Epoch 410/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 20671.3066 - val_loss: 16425.0137\n",
      "Epoch 411/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20595.1641 - val_loss: 16246.8115\n",
      "Epoch 412/1000\n",
      "231/231 [==============================] - 1s 2ms/step - loss: 20726.0176 - val_loss: 17709.7617\n",
      "Epoch 413/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20569.5527 - val_loss: 15961.2100\n",
      "Epoch 414/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20477.6953 - val_loss: 16214.5771\n",
      "Epoch 415/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20592.7578 - val_loss: 16486.1875\n",
      "Epoch 416/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20562.3359 - val_loss: 16180.8838\n",
      "Epoch 417/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20634.9414 - val_loss: 16400.8633\n",
      "Epoch 418/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20144.6699 - val_loss: 16283.0938\n",
      "Epoch 419/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20651.7031 - val_loss: 16198.2373\n",
      "Epoch 420/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20775.7344 - val_loss: 16135.6582\n",
      "Epoch 421/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20620.0762 - val_loss: 15992.5820\n",
      "Epoch 422/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20713.7031 - val_loss: 16250.3330\n",
      "Epoch 423/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20666.3828 - val_loss: 16140.9619\n",
      "Epoch 424/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20311.4785 - val_loss: 17889.1016\n",
      "Epoch 425/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20682.4805 - val_loss: 15989.9326\n",
      "Epoch 426/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20335.8379 - val_loss: 16182.1113\n",
      "Epoch 427/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20747.8516 - val_loss: 15881.7607\n",
      "Epoch 428/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20693.3320 - val_loss: 17160.5156\n",
      "Epoch 429/1000\n",
      "231/231 [==============================] - 0s 945us/step - loss: 20491.9922 - val_loss: 16330.6650\n",
      "Epoch 430/1000\n",
      "231/231 [==============================] - 0s 942us/step - loss: 20703.1836 - val_loss: 15823.2930\n",
      "Epoch 431/1000\n",
      "231/231 [==============================] - 0s 936us/step - loss: 20460.9766 - val_loss: 16020.4180\n",
      "Epoch 432/1000\n",
      "231/231 [==============================] - 0s 942us/step - loss: 20827.9277 - val_loss: 18338.8223\n",
      "Epoch 433/1000\n",
      "231/231 [==============================] - 0s 936us/step - loss: 20664.9082 - val_loss: 16062.8574\n",
      "Epoch 434/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 20066.9512 - val_loss: 16365.5977\n",
      "Epoch 435/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 20160.0254 - val_loss: 16102.4746\n",
      "Epoch 436/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 20188.9570 - val_loss: 16096.8125\n",
      "Epoch 437/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 20153.8574 - val_loss: 15940.4072\n",
      "Epoch 438/1000\n",
      "231/231 [==============================] - 0s 939us/step - loss: 20130.5781 - val_loss: 16270.1523\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 937us/step - loss: 20177.6211 - val_loss: 16557.6562\n",
      "Epoch 440/1000\n",
      "231/231 [==============================] - 0s 895us/step - loss: 20616.3906 - val_loss: 15939.0195\n",
      "Epoch 441/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 20405.0156 - val_loss: 16190.4648\n",
      "Epoch 442/1000\n",
      "231/231 [==============================] - 0s 850us/step - loss: 20249.1777 - val_loss: 15788.8193\n",
      "Epoch 443/1000\n",
      "231/231 [==============================] - 0s 873us/step - loss: 19921.2266 - val_loss: 17115.9043\n",
      "Epoch 444/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20331.5000 - val_loss: 17292.9609\n",
      "Epoch 445/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19920.0586 - val_loss: 17369.0508\n",
      "Epoch 446/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20324.0312 - val_loss: 16570.1387\n",
      "Epoch 447/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20305.8945 - val_loss: 19760.3164\n",
      "Epoch 448/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20170.6523 - val_loss: 16957.4336\n",
      "Epoch 449/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20335.1484 - val_loss: 16211.9170\n",
      "Epoch 450/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20082.3262 - val_loss: 15655.3223\n",
      "Epoch 451/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20149.9199 - val_loss: 16012.5322\n",
      "Epoch 452/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19957.3848 - val_loss: 20756.9688\n",
      "Epoch 453/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20080.8281 - val_loss: 15718.8877\n",
      "Epoch 454/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 19929.4492 - val_loss: 17390.0801\n",
      "Epoch 455/1000\n",
      "231/231 [==============================] - 0s 934us/step - loss: 19873.7676 - val_loss: 15896.0449\n",
      "Epoch 456/1000\n",
      "231/231 [==============================] - 0s 942us/step - loss: 20061.4219 - val_loss: 15814.6289\n",
      "Epoch 457/1000\n",
      "231/231 [==============================] - 0s 871us/step - loss: 19789.4609 - val_loss: 15472.5732\n",
      "Epoch 458/1000\n",
      "231/231 [==============================] - 0s 939us/step - loss: 20069.5703 - val_loss: 16417.5000\n",
      "Epoch 459/1000\n",
      "231/231 [==============================] - 0s 913us/step - loss: 19984.5293 - val_loss: 16183.3018\n",
      "Epoch 460/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 19996.1348 - val_loss: 15399.2129\n",
      "Epoch 461/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 20016.4551 - val_loss: 15394.1494\n",
      "Epoch 462/1000\n",
      "231/231 [==============================] - 0s 924us/step - loss: 19974.7383 - val_loss: 15817.1387\n",
      "Epoch 463/1000\n",
      "231/231 [==============================] - 0s 953us/step - loss: 19875.2109 - val_loss: 15372.0898\n",
      "Epoch 464/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 19925.1543 - val_loss: 16073.8164\n",
      "Epoch 465/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 20220.3477 - val_loss: 17132.8828\n",
      "Epoch 466/1000\n",
      "231/231 [==============================] - 0s 890us/step - loss: 19854.6250 - val_loss: 18754.0547\n",
      "Epoch 467/1000\n",
      "231/231 [==============================] - 0s 953us/step - loss: 20081.5781 - val_loss: 16827.6582\n",
      "Epoch 468/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 20068.0938 - val_loss: 15430.0957\n",
      "Epoch 469/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 20060.2402 - val_loss: 15415.6328\n",
      "Epoch 470/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19725.9668 - val_loss: 15488.1367\n",
      "Epoch 471/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19963.2969 - val_loss: 16230.9893\n",
      "Epoch 472/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19774.4355 - val_loss: 16096.0117\n",
      "Epoch 473/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19284.0117 - val_loss: 16022.0576\n",
      "Epoch 474/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19713.7383 - val_loss: 15786.9932\n",
      "Epoch 475/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19838.8301 - val_loss: 15415.8545\n",
      "Epoch 476/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19475.4023 - val_loss: 15423.7812\n",
      "Epoch 477/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19772.2305 - val_loss: 15680.0889\n",
      "Epoch 478/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19656.2090 - val_loss: 15179.9062\n",
      "Epoch 479/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19566.6797 - val_loss: 16039.1855\n",
      "Epoch 480/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19673.9590 - val_loss: 15704.5371\n",
      "Epoch 481/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19592.8066 - val_loss: 16946.5020\n",
      "Epoch 482/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20061.1777 - val_loss: 15410.3643\n",
      "Epoch 483/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19468.4297 - val_loss: 15181.4209\n",
      "Epoch 484/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 20016.5938 - val_loss: 16826.9258\n",
      "Epoch 485/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19864.0254 - val_loss: 16476.9434\n",
      "Epoch 486/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19698.5762 - val_loss: 16197.2549\n",
      "Epoch 487/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19555.6895 - val_loss: 16111.7090\n",
      "Epoch 488/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19370.7500 - val_loss: 16000.9131\n",
      "Epoch 489/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19489.3008 - val_loss: 15058.1660\n",
      "Epoch 490/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19502.1426 - val_loss: 16644.2500\n",
      "Epoch 491/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19619.1309 - val_loss: 15630.5391\n",
      "Epoch 492/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19489.0293 - val_loss: 15706.5098\n",
      "Epoch 493/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19566.5234 - val_loss: 15197.9502\n",
      "Epoch 494/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19429.5566 - val_loss: 15168.5498\n",
      "Epoch 495/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19527.3203 - val_loss: 15911.3574\n",
      "Epoch 496/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19471.1836 - val_loss: 15885.2568\n",
      "Epoch 497/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19135.6484 - val_loss: 15645.2578\n",
      "Epoch 498/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19587.5586 - val_loss: 15072.6504\n",
      "Epoch 499/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19322.4609 - val_loss: 16370.9951\n",
      "Epoch 500/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19572.2734 - val_loss: 15144.7520\n",
      "Epoch 501/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19388.2090 - val_loss: 16099.4268\n",
      "Epoch 502/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19394.4395 - val_loss: 15306.3428\n",
      "Epoch 503/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19389.7168 - val_loss: 14862.9600\n",
      "Epoch 504/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19456.3789 - val_loss: 15673.0811\n",
      "Epoch 505/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19414.6953 - val_loss: 14949.7871\n",
      "Epoch 506/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19248.9766 - val_loss: 14949.6396\n",
      "Epoch 507/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19834.8438 - val_loss: 15597.0068\n",
      "Epoch 508/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19123.1250 - val_loss: 14818.5820\n",
      "Epoch 509/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19283.2656 - val_loss: 16518.8867\n",
      "Epoch 510/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19273.2539 - val_loss: 14930.9355\n",
      "Epoch 511/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18775.0547 - val_loss: 14963.2949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19850.5781 - val_loss: 16092.7812\n",
      "Epoch 513/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19098.8418 - val_loss: 14967.2080\n",
      "Epoch 514/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19390.2734 - val_loss: 14730.2354\n",
      "Epoch 515/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19296.9609 - val_loss: 15007.5195\n",
      "Epoch 516/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19249.2402 - val_loss: 17008.9238\n",
      "Epoch 517/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19462.8477 - val_loss: 16497.4473\n",
      "Epoch 518/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18943.0996 - val_loss: 15102.9131\n",
      "Epoch 519/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19499.4434 - val_loss: 15682.1748\n",
      "Epoch 520/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19144.9883 - val_loss: 15416.6982\n",
      "Epoch 521/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19213.3008 - val_loss: 15432.4717\n",
      "Epoch 522/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19044.7422 - val_loss: 16508.4629\n",
      "Epoch 523/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19391.6172 - val_loss: 16278.1035\n",
      "Epoch 524/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19151.1582 - val_loss: 17116.8535\n",
      "Epoch 525/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19275.5371 - val_loss: 15208.3955\n",
      "Epoch 526/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19409.4121 - val_loss: 15309.7900\n",
      "Epoch 527/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19294.3359 - val_loss: 16382.7578\n",
      "Epoch 528/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19321.6738 - val_loss: 16962.2988\n",
      "Epoch 529/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19178.8477 - val_loss: 15936.2891\n",
      "Epoch 530/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18843.8145 - val_loss: 15819.9844\n",
      "Epoch 531/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19088.5879 - val_loss: 15348.2773\n",
      "Epoch 532/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18650.0293 - val_loss: 15615.9932\n",
      "Epoch 533/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19262.6035 - val_loss: 15167.1729\n",
      "Epoch 534/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18896.8047 - val_loss: 14865.6553\n",
      "Epoch 535/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18783.1289 - val_loss: 15501.2188\n",
      "Epoch 536/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18984.2949 - val_loss: 14895.2461\n",
      "Epoch 537/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19063.8125 - val_loss: 16652.3574\n",
      "Epoch 538/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18967.2617 - val_loss: 14915.6846\n",
      "Epoch 539/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19302.5859 - val_loss: 15309.3154\n",
      "Epoch 540/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18803.3281 - val_loss: 16122.7207\n",
      "Epoch 541/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18822.7090 - val_loss: 16119.7959\n",
      "Epoch 542/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18914.8516 - val_loss: 14910.0762\n",
      "Epoch 543/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18588.3164 - val_loss: 16113.2617\n",
      "Epoch 544/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18860.8867 - val_loss: 16235.8164\n",
      "Epoch 545/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19108.0059 - val_loss: 16485.6172\n",
      "Epoch 546/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19052.0391 - val_loss: 15193.9668\n",
      "Epoch 547/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18922.8047 - val_loss: 16901.1094\n",
      "Epoch 548/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19093.7754 - val_loss: 15095.3154\n",
      "Epoch 549/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18561.9199 - val_loss: 16283.7715\n",
      "Epoch 550/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18982.0117 - val_loss: 16128.4658\n",
      "Epoch 551/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18813.2188 - val_loss: 16184.9844\n",
      "Epoch 552/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18725.8633 - val_loss: 14740.8838\n",
      "Epoch 553/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18871.0820 - val_loss: 16331.3672\n",
      "Epoch 554/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18819.1406 - val_loss: 15111.0273\n",
      "Epoch 555/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18801.5156 - val_loss: 14595.3604\n",
      "Epoch 556/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18649.1484 - val_loss: 15003.9375\n",
      "Epoch 557/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19273.5586 - val_loss: 15007.0000\n",
      "Epoch 558/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18738.8945 - val_loss: 14594.5498\n",
      "Epoch 559/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18913.5391 - val_loss: 14697.5059\n",
      "Epoch 560/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18848.3066 - val_loss: 14516.0908\n",
      "Epoch 561/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18716.6992 - val_loss: 14985.3555\n",
      "Epoch 562/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18709.4082 - val_loss: 16439.2539\n",
      "Epoch 563/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18602.9844 - val_loss: 14883.0645\n",
      "Epoch 564/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18834.6484 - val_loss: 14701.8809\n",
      "Epoch 565/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18716.4629 - val_loss: 14554.0869\n",
      "Epoch 566/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18522.6016 - val_loss: 15704.4561\n",
      "Epoch 567/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18914.9102 - val_loss: 16314.4590\n",
      "Epoch 568/1000\n",
      "231/231 [==============================] - 0s 953us/step - loss: 18410.2520 - val_loss: 14760.2344\n",
      "Epoch 569/1000\n",
      "231/231 [==============================] - 0s 968us/step - loss: 18990.6797 - val_loss: 20403.0918\n",
      "Epoch 570/1000\n",
      "231/231 [==============================] - 0s 916us/step - loss: 19010.1680 - val_loss: 14422.0703\n",
      "Epoch 571/1000\n",
      "231/231 [==============================] - 0s 952us/step - loss: 18966.6523 - val_loss: 14624.1904\n",
      "Epoch 572/1000\n",
      "231/231 [==============================] - 0s 954us/step - loss: 18497.3008 - val_loss: 14987.7451\n",
      "Epoch 573/1000\n",
      "231/231 [==============================] - 0s 915us/step - loss: 18522.8047 - val_loss: 16864.2969\n",
      "Epoch 574/1000\n",
      "231/231 [==============================] - 0s 976us/step - loss: 18540.4551 - val_loss: 17291.5781\n",
      "Epoch 575/1000\n",
      "231/231 [==============================] - 0s 916us/step - loss: 18692.3047 - val_loss: 14366.5322\n",
      "Epoch 576/1000\n",
      "231/231 [==============================] - 0s 907us/step - loss: 18497.8691 - val_loss: 14951.6084\n",
      "Epoch 577/1000\n",
      "231/231 [==============================] - 0s 910us/step - loss: 18525.7891 - val_loss: 17161.1953\n",
      "Epoch 578/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18809.5293 - val_loss: 14864.5010\n",
      "Epoch 579/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18711.1582 - val_loss: 15226.0469\n",
      "Epoch 580/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18364.3516 - val_loss: 14729.8750\n",
      "Epoch 581/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18416.5566 - val_loss: 14541.3691\n",
      "Epoch 582/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18859.8457 - val_loss: 16395.1230\n",
      "Epoch 583/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18463.4727 - val_loss: 14332.4307\n",
      "Epoch 584/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18940.8359 - val_loss: 14753.6777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 19241.6055 - val_loss: 14846.8477\n",
      "Epoch 586/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18476.4512 - val_loss: 15455.6641\n",
      "Epoch 587/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18343.2715 - val_loss: 14442.7686\n",
      "Epoch 588/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18841.4062 - val_loss: 16280.2861\n",
      "Epoch 589/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18820.3008 - val_loss: 16854.0820\n",
      "Epoch 590/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18325.8828 - val_loss: 14900.9824\n",
      "Epoch 591/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18513.7188 - val_loss: 14636.6260\n",
      "Epoch 592/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18321.6016 - val_loss: 15415.6396\n",
      "Epoch 593/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 18775.1641 - val_loss: 19237.9551\n",
      "Epoch 594/1000\n",
      "231/231 [==============================] - 0s 929us/step - loss: 18389.9512 - val_loss: 15722.2812\n",
      "Epoch 595/1000\n",
      "231/231 [==============================] - 0s 947us/step - loss: 18669.7891 - val_loss: 14962.2256\n",
      "Epoch 596/1000\n",
      "231/231 [==============================] - 0s 932us/step - loss: 18350.5957 - val_loss: 18298.7227\n",
      "Epoch 597/1000\n",
      "231/231 [==============================] - 0s 909us/step - loss: 18805.5273 - val_loss: 19827.4219\n",
      "Epoch 598/1000\n",
      "231/231 [==============================] - 0s 908us/step - loss: 19233.7480 - val_loss: 15912.9102\n",
      "Epoch 599/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 18678.2422 - val_loss: 14732.0312\n",
      "Epoch 600/1000\n",
      "231/231 [==============================] - 0s 936us/step - loss: 18739.7500 - val_loss: 14256.2822\n",
      "Epoch 601/1000\n",
      "231/231 [==============================] - 0s 990us/step - loss: 18333.1562 - val_loss: 15792.4717\n",
      "Epoch 602/1000\n",
      "231/231 [==============================] - 0s 965us/step - loss: 18274.3691 - val_loss: 14202.4746\n",
      "Epoch 603/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 18225.0820 - val_loss: 15354.4424\n",
      "Epoch 604/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18321.1328 - val_loss: 14245.8848\n",
      "Epoch 605/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18295.5000 - val_loss: 18680.9160\n",
      "Epoch 606/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18022.4082 - val_loss: 14550.1875\n",
      "Epoch 607/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18457.8594 - val_loss: 14156.0986\n",
      "Epoch 608/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18660.1035 - val_loss: 14444.0352\n",
      "Epoch 609/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18618.2305 - val_loss: 14931.9170\n",
      "Epoch 610/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18098.6543 - val_loss: 14505.7148\n",
      "Epoch 611/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18153.9688 - val_loss: 14331.0566\n",
      "Epoch 612/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18034.4531 - val_loss: 14569.3672\n",
      "Epoch 613/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17687.6504 - val_loss: 14654.3828\n",
      "Epoch 614/1000\n",
      "231/231 [==============================] - 0s 882us/step - loss: 18728.5508 - val_loss: 14652.9912\n",
      "Epoch 615/1000\n",
      "231/231 [==============================] - 0s 929us/step - loss: 18386.7246 - val_loss: 14625.1748\n",
      "Epoch 616/1000\n",
      "231/231 [==============================] - 0s 927us/step - loss: 18157.6562 - val_loss: 17477.6562\n",
      "Epoch 617/1000\n",
      "231/231 [==============================] - 0s 933us/step - loss: 18735.2734 - val_loss: 15876.9062\n",
      "Epoch 618/1000\n",
      "231/231 [==============================] - 0s 914us/step - loss: 18331.4062 - val_loss: 14544.7363\n",
      "Epoch 619/1000\n",
      "231/231 [==============================] - 0s 924us/step - loss: 18520.2188 - val_loss: 14704.4229\n",
      "Epoch 620/1000\n",
      "231/231 [==============================] - 0s 963us/step - loss: 17917.4609 - val_loss: 14934.5059\n",
      "Epoch 621/1000\n",
      "231/231 [==============================] - 0s 891us/step - loss: 17911.9785 - val_loss: 14593.2891\n",
      "Epoch 622/1000\n",
      "231/231 [==============================] - 0s 921us/step - loss: 18295.6367 - val_loss: 14681.3047\n",
      "Epoch 623/1000\n",
      "231/231 [==============================] - 0s 935us/step - loss: 17952.3828 - val_loss: 14817.9707\n",
      "Epoch 624/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18300.0137 - val_loss: 16076.1035\n",
      "Epoch 625/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18538.9590 - val_loss: 14544.9980\n",
      "Epoch 626/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18230.9453 - val_loss: 14568.8682\n",
      "Epoch 627/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18317.6602 - val_loss: 16760.5762\n",
      "Epoch 628/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18398.5859 - val_loss: 14398.3730\n",
      "Epoch 629/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18555.1191 - val_loss: 16483.4805\n",
      "Epoch 630/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18064.6777 - val_loss: 14825.9912\n",
      "Epoch 631/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18529.2969 - val_loss: 15520.7500\n",
      "Epoch 632/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17865.1035 - val_loss: 14118.6016\n",
      "Epoch 633/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17630.1641 - val_loss: 14966.9844\n",
      "Epoch 634/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18048.7109 - val_loss: 15374.5039\n",
      "Epoch 635/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18182.8496 - val_loss: 14148.5537\n",
      "Epoch 636/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18430.5254 - val_loss: 14365.9893\n",
      "Epoch 637/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17765.9082 - val_loss: 15636.6709\n",
      "Epoch 638/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17859.4180 - val_loss: 14167.3535\n",
      "Epoch 639/1000\n",
      "231/231 [==============================] - ETA: 0s - loss: 17812.7695- ETA: 0s - loss: 17414 - 0s 2ms/step - loss: 17973.7812 - val_loss: 18342.8086\n",
      "Epoch 640/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18337.1758 - val_loss: 13976.7959\n",
      "Epoch 641/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18305.3066 - val_loss: 14316.9482\n",
      "Epoch 642/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18211.5078 - val_loss: 15219.4346\n",
      "Epoch 643/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18187.3594 - val_loss: 14567.2549\n",
      "Epoch 644/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17971.7676 - val_loss: 15171.2812\n",
      "Epoch 645/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17976.5898 - val_loss: 14159.7109\n",
      "Epoch 646/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17892.9180 - val_loss: 14509.6104\n",
      "Epoch 647/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17608.2012 - val_loss: 14991.4834\n",
      "Epoch 648/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18090.8359 - val_loss: 14706.3916\n",
      "Epoch 649/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17783.7266 - val_loss: 14130.3223\n",
      "Epoch 650/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18001.7871 - val_loss: 14551.1729\n",
      "Epoch 651/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17860.1348 - val_loss: 14264.6572\n",
      "Epoch 652/1000\n",
      "231/231 [==============================] - ETA: 0s - loss: 17568.519 - 0s 2ms/step - loss: 17677.7871 - val_loss: 14272.3027\n",
      "Epoch 653/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17906.5332 - val_loss: 16978.2578\n",
      "Epoch 654/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18157.2910 - val_loss: 17446.8770\n",
      "Epoch 655/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17992.2871 - val_loss: 14125.6152\n",
      "Epoch 656/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18038.8828 - val_loss: 15979.9033\n",
      "Epoch 657/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 18189.4277 - val_loss: 16759.4727\n",
      "Epoch 658/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18044.4512 - val_loss: 14460.3730\n",
      "Epoch 659/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18115.5645 - val_loss: 15588.2500\n",
      "Epoch 660/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17990.7129 - val_loss: 14325.4346\n",
      "Epoch 661/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17823.1660 - val_loss: 14772.0176\n",
      "Epoch 662/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17826.0000 - val_loss: 14150.8027\n",
      "Epoch 663/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17694.5215 - val_loss: 14659.3271\n",
      "Epoch 664/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17893.6270 - val_loss: 14291.0088\n",
      "Epoch 665/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17856.8613 - val_loss: 14332.3037\n",
      "Epoch 666/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17638.7012 - val_loss: 13723.9258\n",
      "Epoch 667/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18366.4922 - val_loss: 14348.6211\n",
      "Epoch 668/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17777.9336 - val_loss: 14587.8232\n",
      "Epoch 669/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18004.5859 - val_loss: 14026.3242\n",
      "Epoch 670/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17944.1719 - val_loss: 14258.7529\n",
      "Epoch 671/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17839.1367 - val_loss: 14852.8232\n",
      "Epoch 672/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17775.4492 - val_loss: 17448.6562\n",
      "Epoch 673/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17828.1055 - val_loss: 13858.5889\n",
      "Epoch 674/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17629.0117 - val_loss: 14782.8789\n",
      "Epoch 675/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17626.7578 - val_loss: 14875.8428\n",
      "Epoch 676/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17511.9336 - val_loss: 16393.4648\n",
      "Epoch 677/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17776.4316 - val_loss: 13841.0312\n",
      "Epoch 678/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17442.9062 - val_loss: 13935.5039\n",
      "Epoch 679/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17839.1641 - val_loss: 14084.3750\n",
      "Epoch 680/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17983.1699 - val_loss: 14285.3184\n",
      "Epoch 681/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17650.2480 - val_loss: 14608.4092\n",
      "Epoch 682/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17652.1621 - val_loss: 13893.3242\n",
      "Epoch 683/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17683.3633 - val_loss: 14409.2959\n",
      "Epoch 684/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17669.3574 - val_loss: 13948.0400\n",
      "Epoch 685/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17583.5879 - val_loss: 14433.9189\n",
      "Epoch 686/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18242.6484 - val_loss: 14385.9326\n",
      "Epoch 687/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 17766.1855 - val_loss: 14889.7783\n",
      "Epoch 688/1000\n",
      "231/231 [==============================] - 0s 897us/step - loss: 17852.8086 - val_loss: 15948.1348\n",
      "Epoch 689/1000\n",
      "231/231 [==============================] - 0s 940us/step - loss: 17824.1816 - val_loss: 17067.9902\n",
      "Epoch 690/1000\n",
      "231/231 [==============================] - 0s 905us/step - loss: 18181.0625 - val_loss: 14307.0654\n",
      "Epoch 691/1000\n",
      "231/231 [==============================] - 0s 945us/step - loss: 17331.9238 - val_loss: 14482.6270\n",
      "Epoch 692/1000\n",
      "231/231 [==============================] - 0s 944us/step - loss: 17555.8555 - val_loss: 15142.0488\n",
      "Epoch 693/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 17716.1484 - val_loss: 14053.2725\n",
      "Epoch 694/1000\n",
      "231/231 [==============================] - 0s 915us/step - loss: 17783.3711 - val_loss: 15602.8096\n",
      "Epoch 695/1000\n",
      "231/231 [==============================] - 0s 908us/step - loss: 18184.0273 - val_loss: 14540.6963\n",
      "Epoch 696/1000\n",
      "231/231 [==============================] - 0s 897us/step - loss: 17835.4102 - val_loss: 14352.8037\n",
      "Epoch 697/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 17408.6328 - val_loss: 14179.9980\n",
      "Epoch 698/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17809.7617 - val_loss: 13845.4795\n",
      "Epoch 699/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17652.1484 - val_loss: 14386.5889\n",
      "Epoch 700/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17701.3398 - val_loss: 14545.6484\n",
      "Epoch 701/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18132.1172 - val_loss: 14679.5771\n",
      "Epoch 702/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17458.5645 - val_loss: 13702.9961\n",
      "Epoch 703/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17543.7383 - val_loss: 15183.2168\n",
      "Epoch 704/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 18057.6543 - val_loss: 14422.7432\n",
      "Epoch 705/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17274.7266 - val_loss: 14072.1689\n",
      "Epoch 706/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17470.9082 - val_loss: 14672.7920\n",
      "Epoch 707/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17711.3281 - val_loss: 14158.6816\n",
      "Epoch 708/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17623.0215 - val_loss: 15501.0430\n",
      "Epoch 709/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17372.9473 - val_loss: 13868.7939\n",
      "Epoch 710/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17775.5664 - val_loss: 15514.6416\n",
      "Epoch 711/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17155.8457 - val_loss: 14170.1836\n",
      "Epoch 712/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17545.1934 - val_loss: 14822.1963\n",
      "Epoch 713/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17371.7148 - val_loss: 15132.4092\n",
      "Epoch 714/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17275.5605 - val_loss: 14041.0137\n",
      "Epoch 715/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17539.8535 - val_loss: 15411.5820\n",
      "Epoch 716/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17607.1309 - val_loss: 16015.8037\n",
      "Epoch 717/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17330.5469 - val_loss: 15063.4541\n",
      "Epoch 718/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17832.7383 - val_loss: 14042.6260\n",
      "Epoch 719/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17153.0527 - val_loss: 14162.2314\n",
      "Epoch 720/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17628.0938 - val_loss: 14560.8564\n",
      "Epoch 721/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17191.1934 - val_loss: 16366.9980\n",
      "Epoch 722/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17416.6973 - val_loss: 14316.3975\n",
      "Epoch 723/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17268.1172 - val_loss: 15800.5791\n",
      "Epoch 724/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17296.6523 - val_loss: 13918.2871\n",
      "Epoch 725/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17529.0430 - val_loss: 15039.6650\n",
      "Epoch 726/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17496.0605 - val_loss: 14975.5195\n",
      "Epoch 727/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17415.2441 - val_loss: 14107.5938\n",
      "Epoch 728/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17754.1016 - val_loss: 14253.6914\n",
      "Epoch 729/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17356.5566 - val_loss: 13924.9863\n",
      "Epoch 730/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 2ms/step - loss: 17261.1738 - val_loss: 14262.1611\n",
      "Epoch 731/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17164.3320 - val_loss: 13659.6631\n",
      "Epoch 732/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17650.8984 - val_loss: 14165.7109\n",
      "Epoch 733/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17162.1875 - val_loss: 14426.4180\n",
      "Epoch 734/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17145.2227 - val_loss: 14025.1807\n",
      "Epoch 735/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17653.9180 - val_loss: 14645.8525\n",
      "Epoch 736/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17161.8789 - val_loss: 14801.9414\n",
      "Epoch 737/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16829.4902 - val_loss: 13983.8330\n",
      "Epoch 738/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17137.9512 - val_loss: 15827.6777\n",
      "Epoch 739/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17485.2129 - val_loss: 14023.1348\n",
      "Epoch 740/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17336.1582 - val_loss: 13984.4590\n",
      "Epoch 741/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17193.3418 - val_loss: 14383.6680\n",
      "Epoch 742/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17502.5801 - val_loss: 14741.2910\n",
      "Epoch 743/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17304.3340 - val_loss: 14008.1113\n",
      "Epoch 744/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17504.2168 - val_loss: 14900.0811\n",
      "Epoch 745/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 17302.3672 - val_loss: 14166.6768\n",
      "Epoch 746/1000\n",
      "231/231 [==============================] - 0s 951us/step - loss: 17301.7598 - val_loss: 14118.8770\n",
      "Epoch 747/1000\n",
      "231/231 [==============================] - 0s 930us/step - loss: 17298.9297 - val_loss: 14107.0322\n",
      "Epoch 748/1000\n",
      "231/231 [==============================] - 0s 932us/step - loss: 17263.5391 - val_loss: 15808.7275\n",
      "Epoch 749/1000\n",
      "231/231 [==============================] - 0s 939us/step - loss: 17763.7754 - val_loss: 14441.5654\n",
      "Epoch 750/1000\n",
      "231/231 [==============================] - 0s 924us/step - loss: 17370.2246 - val_loss: 13600.6807\n",
      "Epoch 751/1000\n",
      "231/231 [==============================] - 0s 934us/step - loss: 17112.5352 - val_loss: 15882.0488\n",
      "Epoch 752/1000\n",
      "231/231 [==============================] - 0s 949us/step - loss: 17345.7480 - val_loss: 13761.8691\n",
      "Epoch 753/1000\n",
      "231/231 [==============================] - 0s 935us/step - loss: 16908.0117 - val_loss: 14128.0605\n",
      "Epoch 754/1000\n",
      "231/231 [==============================] - 0s 906us/step - loss: 17124.8145 - val_loss: 14969.7539\n",
      "Epoch 755/1000\n",
      "231/231 [==============================] - 0s 926us/step - loss: 17199.1289 - val_loss: 13622.5420\n",
      "Epoch 756/1000\n",
      "231/231 [==============================] - 0s 955us/step - loss: 16804.3965 - val_loss: 14166.5977\n",
      "Epoch 757/1000\n",
      "231/231 [==============================] - 0s 906us/step - loss: 16902.3418 - val_loss: 14487.9707\n",
      "Epoch 758/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16833.7285 - val_loss: 13811.4805\n",
      "Epoch 759/1000\n",
      "231/231 [==============================] - 0s 883us/step - loss: 17287.3672 - val_loss: 15205.7227\n",
      "Epoch 760/1000\n",
      "231/231 [==============================] - 0s 930us/step - loss: 17026.4434 - val_loss: 13830.7500\n",
      "Epoch 761/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17086.3613 - val_loss: 13586.4014\n",
      "Epoch 762/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17288.4844 - val_loss: 13531.1533\n",
      "Epoch 763/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17417.9844 - val_loss: 13784.0801\n",
      "Epoch 764/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17571.3086 - val_loss: 13822.5967\n",
      "Epoch 765/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17151.4004 - val_loss: 15124.3105\n",
      "Epoch 766/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17213.4277 - val_loss: 14125.7520\n",
      "Epoch 767/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17594.5137 - val_loss: 13619.3633\n",
      "Epoch 768/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17014.5078 - val_loss: 13829.3320\n",
      "Epoch 769/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16736.7832 - val_loss: 13763.2236\n",
      "Epoch 770/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17197.9258 - val_loss: 15021.5791\n",
      "Epoch 771/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16694.9355 - val_loss: 14466.0439\n",
      "Epoch 772/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17396.2734 - val_loss: 14422.4814\n",
      "Epoch 773/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16804.2305 - val_loss: 14978.9893\n",
      "Epoch 774/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17651.7734 - val_loss: 17091.4746\n",
      "Epoch 775/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17333.1445 - val_loss: 15058.4141\n",
      "Epoch 776/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17032.7109 - val_loss: 14733.5615\n",
      "Epoch 777/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17124.2109 - val_loss: 14475.9551\n",
      "Epoch 778/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16905.1113 - val_loss: 15838.7500\n",
      "Epoch 779/1000\n",
      "231/231 [==============================] - 0s 941us/step - loss: 17201.2109 - val_loss: 14391.1348\n",
      "Epoch 780/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 17295.6270 - val_loss: 14018.2266\n",
      "Epoch 781/1000\n",
      "231/231 [==============================] - 0s 942us/step - loss: 17208.4434 - val_loss: 16994.4746\n",
      "Epoch 782/1000\n",
      "231/231 [==============================] - 0s 853us/step - loss: 17092.5391 - val_loss: 15777.4248\n",
      "Epoch 783/1000\n",
      "231/231 [==============================] - 0s 961us/step - loss: 17174.6289 - val_loss: 14597.5146\n",
      "Epoch 784/1000\n",
      "231/231 [==============================] - 0s 933us/step - loss: 17027.9102 - val_loss: 13792.6172\n",
      "Epoch 785/1000\n",
      "231/231 [==============================] - 0s 933us/step - loss: 16959.9414 - val_loss: 14014.6406\n",
      "Epoch 786/1000\n",
      "231/231 [==============================] - 0s 946us/step - loss: 16801.5508 - val_loss: 13773.8223\n",
      "Epoch 787/1000\n",
      "231/231 [==============================] - 0s 944us/step - loss: 17053.7109 - val_loss: 13936.7031\n",
      "Epoch 788/1000\n",
      "231/231 [==============================] - 0s 961us/step - loss: 17045.9727 - val_loss: 15574.5771\n",
      "Epoch 789/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17137.3516 - val_loss: 14046.3359\n",
      "Epoch 790/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16969.6582 - val_loss: 13748.8965\n",
      "Epoch 791/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16899.4551 - val_loss: 14503.0527\n",
      "Epoch 792/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17532.6230 - val_loss: 17209.4355\n",
      "Epoch 793/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16713.5020 - val_loss: 13830.3076\n",
      "Epoch 794/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16994.6309 - val_loss: 14415.0234\n",
      "Epoch 795/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17050.0664 - val_loss: 17103.9551\n",
      "Epoch 796/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16853.9102 - val_loss: 13611.8379\n",
      "Epoch 797/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17162.3633 - val_loss: 13921.9688\n",
      "Epoch 798/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16631.9453 - val_loss: 13584.2744\n",
      "Epoch 799/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16872.2363 - val_loss: 14428.8965\n",
      "Epoch 800/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17182.1758 - val_loss: 16822.3301\n",
      "Epoch 801/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17049.2266 - val_loss: 14130.6504\n",
      "Epoch 802/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16853.0918 - val_loss: 14149.9932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17003.1465 - val_loss: 14020.3447\n",
      "Epoch 804/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16876.8730 - val_loss: 14459.0586\n",
      "Epoch 805/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16940.3848 - val_loss: 13873.9014\n",
      "Epoch 806/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16955.4824 - val_loss: 14345.1318\n",
      "Epoch 807/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16826.8965 - val_loss: 13805.0703\n",
      "Epoch 808/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17185.7734 - val_loss: 13680.5381\n",
      "Epoch 809/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17079.0879 - val_loss: 15160.8027\n",
      "Epoch 810/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16995.9648 - val_loss: 14952.7520\n",
      "Epoch 811/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16934.3770 - val_loss: 14467.9062\n",
      "Epoch 812/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16766.8047 - val_loss: 14265.0049\n",
      "Epoch 813/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16810.5156 - val_loss: 14557.7764\n",
      "Epoch 814/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17160.3047 - val_loss: 15426.7920\n",
      "Epoch 815/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16563.9395 - val_loss: 14115.0439\n",
      "Epoch 816/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16547.5488 - val_loss: 14667.2197\n",
      "Epoch 817/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16672.1934 - val_loss: 14648.0869\n",
      "Epoch 818/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17125.8203 - val_loss: 14447.6484\n",
      "Epoch 819/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16601.1758 - val_loss: 13868.0166\n",
      "Epoch 820/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16824.2598 - val_loss: 14578.4629\n",
      "Epoch 821/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17008.1738 - val_loss: 15046.9531\n",
      "Epoch 822/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16737.3750 - val_loss: 13950.7998\n",
      "Epoch 823/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17276.9746 - val_loss: 13683.2285\n",
      "Epoch 824/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16867.4609 - val_loss: 14663.0713\n",
      "Epoch 825/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16860.2754 - val_loss: 14279.8008\n",
      "Epoch 826/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16806.8457 - val_loss: 14101.1260\n",
      "Epoch 827/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16951.8242 - val_loss: 15167.4961\n",
      "Epoch 828/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16892.9883 - val_loss: 14009.4580\n",
      "Epoch 829/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16638.8574 - val_loss: 17261.6426\n",
      "Epoch 830/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16778.8984 - val_loss: 13602.0635\n",
      "Epoch 831/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16506.7930 - val_loss: 14354.7041\n",
      "Epoch 832/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16945.6289 - val_loss: 14925.7363\n",
      "Epoch 833/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16735.1777 - val_loss: 13582.3574\n",
      "Epoch 834/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16766.2207 - val_loss: 13992.8916\n",
      "Epoch 835/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17045.6133 - val_loss: 14050.7041\n",
      "Epoch 836/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16642.6289 - val_loss: 14121.9424\n",
      "Epoch 837/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17444.3613 - val_loss: 14368.3691\n",
      "Epoch 838/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16942.3242 - val_loss: 13809.9395\n",
      "Epoch 839/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16807.9531 - val_loss: 14256.1094\n",
      "Epoch 840/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16698.3555 - val_loss: 14145.3906\n",
      "Epoch 841/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16125.9424 - val_loss: 14509.5938\n",
      "Epoch 842/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16680.4590 - val_loss: 14309.1787\n",
      "Epoch 843/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16559.7734 - val_loss: 15149.8975\n",
      "Epoch 844/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16983.2344 - val_loss: 15269.8428\n",
      "Epoch 845/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16491.4492 - val_loss: 13853.7197\n",
      "Epoch 846/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16895.8457 - val_loss: 16741.2129\n",
      "Epoch 847/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16767.8770 - val_loss: 13866.5391\n",
      "Epoch 848/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16453.5977 - val_loss: 14232.9893\n",
      "Epoch 849/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17035.0430 - val_loss: 14601.7471\n",
      "Epoch 850/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17134.3789 - val_loss: 13958.5508\n",
      "Epoch 851/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16644.9297 - val_loss: 14281.4961\n",
      "Epoch 852/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16491.6016 - val_loss: 16498.1367\n",
      "Epoch 853/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17015.8887 - val_loss: 14211.7500\n",
      "Epoch 854/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17364.4648 - val_loss: 13722.7588\n",
      "Epoch 855/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16800.5234 - val_loss: 14001.4287\n",
      "Epoch 856/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16616.1699 - val_loss: 13889.3125\n",
      "Epoch 857/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17165.0176 - val_loss: 14392.1377\n",
      "Epoch 858/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16583.4707 - val_loss: 14387.0498\n",
      "Epoch 859/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16522.5547 - val_loss: 13770.7412\n",
      "Epoch 860/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17172.2754 - val_loss: 14226.9883\n",
      "Epoch 861/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16233.2764 - val_loss: 13827.2783\n",
      "Epoch 862/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16759.3496 - val_loss: 16390.0547\n",
      "Epoch 863/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16621.0352 - val_loss: 16289.0195\n",
      "Epoch 864/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 17585.2539 - val_loss: 14705.0957\n",
      "Epoch 865/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16734.2910 - val_loss: 19140.2734\n",
      "Epoch 866/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16575.8438 - val_loss: 14394.7510\n",
      "Epoch 867/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16584.8594 - val_loss: 14904.1816\n",
      "Epoch 868/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16701.0254 - val_loss: 15580.1250\n",
      "Epoch 869/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16815.7832 - val_loss: 14908.9727\n",
      "Epoch 870/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16696.5176 - val_loss: 14050.2090\n",
      "Epoch 871/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16419.7363 - val_loss: 15437.9531\n",
      "Epoch 872/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16832.0742 - val_loss: 14165.2422\n",
      "Epoch 873/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16668.6992 - val_loss: 14538.2236\n",
      "Epoch 874/1000\n",
      "231/231 [==============================] - ETA: 0s - loss: 16383.072 - 0s 2ms/step - loss: 16434.0781 - val_loss: 13933.5957\n",
      "Epoch 875/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16546.8047 - val_loss: 13932.3555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 876/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16165.8105 - val_loss: 16047.5889\n",
      "Epoch 877/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16331.0068 - val_loss: 13961.9512\n",
      "Epoch 878/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16423.7051 - val_loss: 15296.9199\n",
      "Epoch 879/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16534.5840 - val_loss: 16016.8975\n",
      "Epoch 880/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16520.1406 - val_loss: 13785.2178\n",
      "Epoch 881/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16562.3203 - val_loss: 15723.0518\n",
      "Epoch 882/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16320.6680 - val_loss: 15025.1367\n",
      "Epoch 883/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16615.7090 - val_loss: 15191.2861\n",
      "Epoch 884/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16049.1357 - val_loss: 14490.9727\n",
      "Epoch 885/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16170.3105 - val_loss: 15084.8213\n",
      "Epoch 886/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16020.5361 - val_loss: 15234.4580\n",
      "Epoch 887/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16717.3887 - val_loss: 14135.1211\n",
      "Epoch 888/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16294.6650 - val_loss: 17333.5566\n",
      "Epoch 889/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16548.9668 - val_loss: 14192.5176\n",
      "Epoch 890/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 16524.6953 - val_loss: 15139.1592\n",
      "Epoch 891/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16609.5156 - val_loss: 14618.6826\n",
      "Epoch 892/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16426.4395 - val_loss: 15456.1611\n",
      "Epoch 893/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16367.7812 - val_loss: 14252.7500\n",
      "Epoch 894/1000\n",
      "231/231 [==============================] - 0s 892us/step - loss: 16402.1074 - val_loss: 14293.3496\n",
      "Epoch 895/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16450.9434 - val_loss: 16642.7754\n",
      "Epoch 896/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16757.7480 - val_loss: 16176.2891\n",
      "Epoch 897/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16522.4141 - val_loss: 13862.9668\n",
      "Epoch 898/1000\n",
      "231/231 [==============================] - 0s 938us/step - loss: 16349.8955 - val_loss: 14327.8574\n",
      "Epoch 899/1000\n",
      "231/231 [==============================] - 0s 871us/step - loss: 16739.0391 - val_loss: 14044.2734\n",
      "Epoch 900/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16143.6875 - val_loss: 14371.1406\n",
      "Epoch 901/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16598.7148 - val_loss: 15594.9736\n",
      "Epoch 902/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16579.6504 - val_loss: 14552.5303\n",
      "Epoch 903/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16503.1973 - val_loss: 13910.7910\n",
      "Epoch 904/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16538.3105 - val_loss: 14144.5146\n",
      "Epoch 905/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16216.9932 - val_loss: 15955.3848\n",
      "Epoch 906/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16214.0361 - val_loss: 15393.4609\n",
      "Epoch 907/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16709.7324 - val_loss: 16877.6211\n",
      "Epoch 908/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16346.6582 - val_loss: 14550.0557\n",
      "Epoch 909/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16390.7305 - val_loss: 15292.9531\n",
      "Epoch 910/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16419.8379 - val_loss: 15308.6934\n",
      "Epoch 911/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16428.8164 - val_loss: 13915.4521\n",
      "Epoch 912/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16264.9023 - val_loss: 15868.6221\n",
      "Epoch 913/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16243.7227 - val_loss: 15099.7764\n",
      "Epoch 914/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16340.3838 - val_loss: 14334.9395\n",
      "Epoch 915/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16456.8652 - val_loss: 14402.6035\n",
      "Epoch 916/1000\n",
      "231/231 [==============================] - 0s 953us/step - loss: 16694.5117 - val_loss: 18352.0938\n",
      "Epoch 917/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16454.8262 - val_loss: 13916.7207\n",
      "Epoch 918/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16416.2109 - val_loss: 14926.9805\n",
      "Epoch 919/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16510.4980 - val_loss: 14102.0654\n",
      "Epoch 920/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 16328.2227 - val_loss: 15000.2080\n",
      "Epoch 921/1000\n",
      "231/231 [==============================] - 0s 943us/step - loss: 16703.5547 - val_loss: 14626.8369\n",
      "Epoch 922/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16116.0039 - val_loss: 15199.1660\n",
      "Epoch 923/1000\n",
      "231/231 [==============================] - 0s 982us/step - loss: 16603.5527 - val_loss: 13886.6035\n",
      "Epoch 924/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16021.9463 - val_loss: 14511.8965\n",
      "Epoch 925/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16617.6797 - val_loss: 16332.9033\n",
      "Epoch 926/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16561.4141 - val_loss: 15459.4434\n",
      "Epoch 927/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16797.8027 - val_loss: 13995.8545\n",
      "Epoch 928/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16180.4727 - val_loss: 14116.3711\n",
      "Epoch 929/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16338.5801 - val_loss: 14623.4209\n",
      "Epoch 930/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16159.2852 - val_loss: 14559.2686\n",
      "Epoch 931/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16379.1562 - val_loss: 16025.2666\n",
      "Epoch 932/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16686.5977 - val_loss: 16425.9902\n",
      "Epoch 933/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16479.3457 - val_loss: 15885.3896\n",
      "Epoch 934/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16407.9922 - val_loss: 13825.3926\n",
      "Epoch 935/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16461.6367 - val_loss: 14644.2842\n",
      "Epoch 936/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16385.3574 - val_loss: 13762.9922\n",
      "Epoch 937/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16432.7969 - val_loss: 14720.4697\n",
      "Epoch 938/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16203.2383 - val_loss: 14229.1006\n",
      "Epoch 939/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16263.6719 - val_loss: 14701.4678\n",
      "Epoch 940/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16182.7275 - val_loss: 14186.2324\n",
      "Epoch 941/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16519.5020 - val_loss: 14027.6846\n",
      "Epoch 942/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16496.0332 - val_loss: 13752.0342\n",
      "Epoch 943/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16620.9219 - val_loss: 13756.0820\n",
      "Epoch 944/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15975.1943 - val_loss: 14528.4043\n",
      "Epoch 945/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16648.2090 - val_loss: 15807.1094\n",
      "Epoch 946/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15980.8857 - val_loss: 14857.3486\n",
      "Epoch 947/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16296.1494 - val_loss: 13955.7686\n",
      "Epoch 948/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15990.0352 - val_loss: 14538.3535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16140.6758 - val_loss: 13942.5479\n",
      "Epoch 950/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16717.8086 - val_loss: 14339.4014\n",
      "Epoch 951/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16591.5527 - val_loss: 13683.0186\n",
      "Epoch 952/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16047.0293 - val_loss: 14237.1514\n",
      "Epoch 953/1000\n",
      "231/231 [==============================] - 0s 951us/step - loss: 16037.5957 - val_loss: 20348.5215\n",
      "Epoch 954/1000\n",
      "231/231 [==============================] - 0s 941us/step - loss: 16340.2432 - val_loss: 14208.3115\n",
      "Epoch 955/1000\n",
      "231/231 [==============================] - 0s 913us/step - loss: 15800.1602 - val_loss: 14251.4209\n",
      "Epoch 956/1000\n",
      "231/231 [==============================] - 0s 956us/step - loss: 15777.7520 - val_loss: 14369.4961\n",
      "Epoch 957/1000\n",
      "231/231 [==============================] - 0s 921us/step - loss: 16495.9277 - val_loss: 14923.0889\n",
      "Epoch 958/1000\n",
      "231/231 [==============================] - 0s 942us/step - loss: 16712.4238 - val_loss: 14431.8975\n",
      "Epoch 959/1000\n",
      "231/231 [==============================] - 0s 936us/step - loss: 16089.5586 - val_loss: 14473.7109\n",
      "Epoch 960/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16401.3379 - val_loss: 14825.7090\n",
      "Epoch 961/1000\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 16415.7227 - val_loss: 14418.8965\n",
      "Epoch 962/1000\n",
      "231/231 [==============================] - 0s 997us/step - loss: 16170.3857 - val_loss: 14004.0693\n",
      "Epoch 963/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15898.6025 - val_loss: 14613.7246\n",
      "Epoch 964/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16614.6719 - val_loss: 14175.6865\n",
      "Epoch 965/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16046.1367 - val_loss: 14029.2979\n",
      "Epoch 966/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15826.1230 - val_loss: 14605.2100\n",
      "Epoch 967/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15839.7539 - val_loss: 13917.8809\n",
      "Epoch 968/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15927.4932 - val_loss: 16398.2051\n",
      "Epoch 969/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16547.6172 - val_loss: 14734.5615\n",
      "Epoch 970/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16017.5273 - val_loss: 14887.1455\n",
      "Epoch 971/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16108.9023 - val_loss: 14233.8799\n",
      "Epoch 972/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16408.3516 - val_loss: 13960.2471\n",
      "Epoch 973/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15989.8730 - val_loss: 17940.3555\n",
      "Epoch 974/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16047.3906 - val_loss: 14950.7939\n",
      "Epoch 975/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15902.1299 - val_loss: 14099.9199\n",
      "Epoch 976/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16266.8330 - val_loss: 15454.4297\n",
      "Epoch 977/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16125.6367 - val_loss: 14038.0273\n",
      "Epoch 978/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16206.8105 - val_loss: 14450.8584\n",
      "Epoch 979/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15966.7363 - val_loss: 14034.0049\n",
      "Epoch 980/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16345.5156 - val_loss: 18313.9766\n",
      "Epoch 981/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16100.7607 - val_loss: 16620.8438\n",
      "Epoch 982/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15895.9326 - val_loss: 18928.3906\n",
      "Epoch 983/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16253.5205 - val_loss: 14758.2236\n",
      "Epoch 984/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16002.6445 - val_loss: 16110.9707\n",
      "Epoch 985/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15924.2705 - val_loss: 14080.7793\n",
      "Epoch 986/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15743.1045 - val_loss: 14252.2080\n",
      "Epoch 987/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16226.2461 - val_loss: 18042.5391\n",
      "Epoch 988/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16058.3086 - val_loss: 15691.7812\n",
      "Epoch 989/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16268.1494 - val_loss: 17696.3535\n",
      "Epoch 990/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16291.1182 - val_loss: 13926.9385\n",
      "Epoch 991/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16406.1270 - val_loss: 14214.0137\n",
      "Epoch 992/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15888.2295 - val_loss: 14304.3965\n",
      "Epoch 993/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16422.1191 - val_loss: 14145.3818\n",
      "Epoch 994/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15801.3281 - val_loss: 14082.9316\n",
      "Epoch 995/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16002.1338 - val_loss: 14898.2373\n",
      "Epoch 996/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16253.3633 - val_loss: 15137.1182\n",
      "Epoch 997/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15989.2539 - val_loss: 14453.5146\n",
      "Epoch 998/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16512.7031 - val_loss: 15652.7109\n",
      "Epoch 999/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 15795.6299 - val_loss: 14674.8477\n",
      "Epoch 1000/1000\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 16086.1162 - val_loss: 14113.5215\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\"))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\"))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\"))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer=\"he_uniform\"))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "ephocs=1000\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs=ephocs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=df_Test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128074.91],\n",
       "       [169098.8 ],\n",
       "       [178167.77],\n",
       "       ...,\n",
       "       [167722.42],\n",
       "       [119884.53],\n",
       "       [219050.58]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-adb577d418da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstack_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstack_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' _'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nStacking Results for trining test : \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stack' is not defined"
     ]
    }
   ],
   "source": [
    "stack_score = round(stack.score(y_pred, y_true)*100, 3)\n",
    "predictions = stack.predict(y_pred)\n",
    "stack_rmse = round(np.sqrt(mean_squared_error(y_true, predictions).mean())*100, 3)\n",
    "print(' _'*15)\n",
    "print('\\nStacking Results for trining test : \\n')\n",
    "print(f'Score : {stack_score}%')\n",
    "print(f'RMSE  : {stack_rmse}%')\n",
    "print(' _'*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
